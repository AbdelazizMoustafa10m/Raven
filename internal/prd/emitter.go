package prd

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"text/template"

	"github.com/charmbracelet/log"
)

// maxTasksForMermaid is the upper bound on tasks for which a Mermaid dependency
// graph is included in INDEX.md. Larger sets are omitted to keep the file readable.
const maxTasksForMermaid = 100

// maxTasksWarning is the threshold at which a warning is logged about large task counts.
const maxTasksWarning = 1000

// Emitter generates all output files from a merged, deduplicated, DAG-validated
// task list. It writes individual task spec files, task-state.conf, phases.conf,
// PROGRESS.md, and INDEX.md to the configured output directory.
type Emitter struct {
	outputDir string
	force     bool
	logger    *log.Logger
}

// EmitterOption is a functional option for Emitter.
type EmitterOption func(*Emitter)

// WithEmitterLogger sets the logger used by the Emitter.
func WithEmitterLogger(logger *log.Logger) EmitterOption {
	return func(e *Emitter) {
		e.logger = logger
	}
}

// WithForce controls whether existing output files are overwritten.
// When false (the default), Emit returns an error if any output file already exists.
func WithForce(force bool) EmitterOption {
	return func(e *Emitter) {
		e.force = force
	}
}

// EmitOpts holds the inputs needed to generate output files.
type EmitOpts struct {
	// Tasks is the final merged, deduplicated task list.
	Tasks []MergedTask
	// Validation holds DAG analysis results including topological depths.
	Validation *DAGValidation
	// Epics provides epic metadata used for phase naming.
	Epics *EpicBreakdown
	// StartID is the starting task number for re-sequencing (default 1).
	StartID int
}

// EmitResult summarises all files generated by Emit.
type EmitResult struct {
	// OutputDir is the directory in which all files were written.
	OutputDir string
	// TaskFiles lists the paths of all generated T-XXX-slug.md files.
	TaskFiles []string
	// TaskStateFile is the path to the generated task-state.conf.
	TaskStateFile string
	// PhasesFile is the path to the generated phases.conf.
	PhasesFile string
	// ProgressFile is the path to the generated PROGRESS.md.
	ProgressFile string
	// IndexFile is the path to the generated INDEX.md.
	IndexFile string
	// TotalTasks is the number of task spec files written.
	TotalTasks int
	// TotalPhases is the number of phases written to phases.conf.
	TotalPhases int
}

// PhaseInfo describes a single phase derived from the topological depth grouping.
type PhaseInfo struct {
	// ID is the 1-based phase number.
	ID int
	// Name is a human-readable phase label.
	Name string
	// StartTask is the lowest GlobalID in the phase (e.g., "T-001").
	StartTask string
	// EndTask is the highest GlobalID in the phase (e.g., "T-010").
	EndTask string
	// Tasks holds the tasks that belong to this phase.
	Tasks []MergedTask
}

// NewEmitter creates an Emitter that writes output files to outputDir.
// Call Emit to generate all files.
func NewEmitter(outputDir string, opts ...EmitterOption) *Emitter {
	e := &Emitter{
		outputDir: outputDir,
		logger:    log.Default(),
	}
	for _, opt := range opts {
		opt(e)
	}
	return e
}

// Emit generates all output files from the merged task data.
// It re-sequences GlobalIDs to close any gaps left by deduplication, assigns
// phases from topological depth, and writes the following files:
//   - T-XXX-slug.md for each task
//   - task-state.conf
//   - phases.conf
//   - PROGRESS.md
//   - INDEX.md
//
// When WithForce(false) (the default), Emit returns an error if any output
// file already exists.
func (e *Emitter) Emit(opts EmitOpts) (*EmitResult, error) {
	// Resolve and validate the output directory path.
	outDir, err := filepath.Abs(e.outputDir)
	if err != nil {
		return nil, fmt.Errorf("resolving output directory: %w", err)
	}

	if len(opts.Tasks) > maxTasksWarning {
		e.logger.Warn("large task count; generation may be slow",
			"count", len(opts.Tasks),
			"threshold", maxTasksWarning,
		)
	}

	// Re-sequence GlobalIDs to close gaps from deduplication, starting from
	// the configured StartID (defaults to 1 when zero or negative).
	tasks, idMap := ResequenceIDs(opts.Tasks, opts.StartID)
	if len(idMap) > 0 {
		e.logger.Debug("re-sequenced task IDs", "remapped", len(idMap))
	}

	// Determine depths map, remapping old IDs to new IDs.
	depths := make(map[string]int)
	if opts.Validation != nil {
		for oldID, depth := range opts.Validation.Depths {
			if newID, ok := idMap[oldID]; ok {
				depths[newID] = depth
			} else {
				// ID was not remapped -- use it directly (no gap for this ID).
				depths[oldID] = depth
			}
		}
	}

	// Assign phases from topological depth.
	phases := AssignPhases(tasks, depths, opts.Epics)

	// Ensure output directory exists.
	if err := os.MkdirAll(outDir, 0755); err != nil {
		return nil, fmt.Errorf("creating output directory %q: %w", outDir, err)
	}

	result := &EmitResult{
		OutputDir:   outDir,
		TotalTasks:  len(tasks),
		TotalPhases: len(phases),
	}

	// Track used slugs to handle collisions.
	usedSlugs := make(map[string]int)

	// --- Write task spec files ---
	taskFiles, err := e.writeTaskFiles(outDir, tasks, usedSlugs)
	if err != nil {
		return nil, err
	}
	result.TaskFiles = taskFiles

	// --- Write task-state.conf ---
	stateFile := filepath.Join(outDir, "task-state.conf")
	if err := e.writeFile(stateFile, e.buildTaskState(tasks)); err != nil {
		return nil, fmt.Errorf("writing task-state.conf: %w", err)
	}
	result.TaskStateFile = stateFile

	// --- Write phases.conf ---
	phasesFile := filepath.Join(outDir, "phases.conf")
	if err := e.writeFile(phasesFile, e.buildPhasesConf(phases)); err != nil {
		return nil, fmt.Errorf("writing phases.conf: %w", err)
	}
	result.PhasesFile = phasesFile

	// --- Write PROGRESS.md ---
	progressFile := filepath.Join(outDir, "PROGRESS.md")
	if err := e.writeFile(progressFile, e.buildProgressMD(tasks, phases)); err != nil {
		return nil, fmt.Errorf("writing PROGRESS.md: %w", err)
	}
	result.ProgressFile = progressFile

	// --- Write INDEX.md ---
	indexFile := filepath.Join(outDir, "INDEX.md")
	if err := e.writeFile(indexFile, e.buildIndexMD(tasks, phases)); err != nil {
		return nil, fmt.Errorf("writing INDEX.md: %w", err)
	}
	result.IndexFile = indexFile

	e.logger.Info("emitted task files",
		"tasks", result.TotalTasks,
		"phases", result.TotalPhases,
		"dir", outDir,
	)

	return result, nil
}

// writeTaskFiles renders one T-XXX-slug.md per task and returns the list of paths.
func (e *Emitter) writeTaskFiles(outDir string, tasks []MergedTask, usedSlugs map[string]int) ([]string, error) {
	paths := make([]string, 0, len(tasks))
	for _, task := range tasks {
		slug := uniqueSlug(task, usedSlugs)
		filename := fmt.Sprintf("%s-%s.md", task.GlobalID, slug)
		path := filepath.Join(outDir, filename)

		content, err := renderTaskFile(task)
		if err != nil {
			return nil, fmt.Errorf("rendering task file for %s: %w", task.GlobalID, err)
		}

		if err := e.writeFile(path, content); err != nil {
			return nil, fmt.Errorf("writing task file %s: %w", filename, err)
		}
		paths = append(paths, path)
	}
	return paths, nil
}

// writeFile writes content to path. When e.force is false, it returns an error
// if the file already exists. Uses atomic write (tmp + rename) for safety.
func (e *Emitter) writeFile(path string, content []byte) error {
	if !e.force {
		if _, err := os.Stat(path); err == nil {
			return fmt.Errorf("file already exists (use --force to overwrite): %s", path)
		}
	}

	tmp := path + ".tmp"
	if err := os.WriteFile(tmp, content, 0o600); err != nil {
		return fmt.Errorf("writing temporary file %s: %w", tmp, err)
	}

	if err := os.Rename(tmp, path); err != nil {
		os.Remove(tmp) //nolint:errcheck
		return fmt.Errorf("renaming %s -> %s: %w", tmp, path, err)
	}
	return nil
}

// ResequenceIDs re-assigns sequential IDs starting from startID (T-{startID},
// T-{startID+1}, ...) to tasks, closing any gaps left by deduplication. All
// Dependencies fields are updated to use the new IDs. The original task
// ordering is preserved. A startID of 0 or less is treated as 1.
//
// Returns the updated task slice and an IDMapping from old GlobalID to new GlobalID.
// Only IDs that actually changed are included in the mapping.
func ResequenceIDs(tasks []MergedTask, startID ...int) ([]MergedTask, IDMapping) {
	if len(tasks) == 0 {
		return nil, IDMapping{}
	}

	start := 1
	if len(startID) > 0 && startID[0] > 0 {
		start = startID[0]
	}

	format := "T-%03d"
	if start+len(tasks)-1 >= 1000 {
		format = "T-%04d"
	}

	// Build the old->new mapping.
	mapping := make(IDMapping, len(tasks))
	hasChanges := false
	for i, task := range tasks {
		newID := fmt.Sprintf(format, start+i)
		if task.GlobalID != newID {
			mapping[task.GlobalID] = newID
			hasChanges = true
		}
	}

	if !hasChanges {
		// No re-sequencing needed; return a copy of the slice.
		out := make([]MergedTask, len(tasks))
		copy(out, tasks)
		return out, IDMapping{}
	}

	// Apply new IDs and remap dependencies.
	out := make([]MergedTask, len(tasks))
	for i, task := range tasks {
		newID := fmt.Sprintf(format, start+i)
		task.GlobalID = newID

		if len(task.Dependencies) > 0 {
			updated := make([]string, 0, len(task.Dependencies))
			for _, dep := range task.Dependencies {
				if remapped, ok := mapping[dep]; ok {
					updated = append(updated, remapped)
				} else {
					// Dep was not remapped (e.g., already had the correct sequential ID).
					updated = append(updated, dep)
				}
			}
			task.Dependencies = updated
		}
		out[i] = task
	}

	return out, mapping
}

// AssignPhases groups tasks by topological depth and returns a slice of PhaseInfo
// values sorted by phase ID. Tasks not present in the depths map are treated as
// depth 0. Within each phase, tasks are sorted by GlobalID.
//
// Phase names are derived from the most common epic title at each depth level.
// When no epics are provided or no common title can be determined, the fallback
// "Phase N" label is used.
func AssignPhases(tasks []MergedTask, depths map[string]int, epics *EpicBreakdown) []PhaseInfo {
	if len(tasks) == 0 {
		return nil
	}

	// Build epic ID -> title lookup.
	epicTitles := make(map[string]string)
	if epics != nil {
		for _, epic := range epics.Epics {
			epicTitles[epic.ID] = epic.Title
		}
	}

	// Group tasks by depth.
	depthGroups := make(map[int][]MergedTask)
	for _, task := range tasks {
		d := 0
		if depths != nil {
			d = depths[task.GlobalID]
		}
		depthGroups[d] = append(depthGroups[d], task)
	}

	// Collect and sort depth values.
	depthValues := make([]int, 0, len(depthGroups))
	for d := range depthGroups {
		depthValues = append(depthValues, d)
	}
	sort.Ints(depthValues)

	phases := make([]PhaseInfo, 0, len(depthValues))
	for phaseNum, depth := range depthValues {
		group := depthGroups[depth]

		// Sort tasks in this phase by GlobalID.
		sort.Slice(group, func(i, j int) bool {
			return group[i].GlobalID < group[j].GlobalID
		})

		// Determine phase name from the most common epic title.
		name := phaseNameFromEpics(phaseNum+1, group, epicTitles)

		// Find start and end task IDs.
		startTask := group[0].GlobalID
		endTask := group[len(group)-1].GlobalID

		phases = append(phases, PhaseInfo{
			ID:        phaseNum + 1,
			Name:      name,
			StartTask: startTask,
			EndTask:   endTask,
			Tasks:     group,
		})
	}

	return phases
}

// phaseNameFromEpics returns the name for a phase based on the most common epic
// title among the tasks in the phase. Falls back to "Phase N".
func phaseNameFromEpics(phaseID int, tasks []MergedTask, epicTitles map[string]string) string {
	if len(epicTitles) == 0 {
		return fmt.Sprintf("Phase %d", phaseID)
	}

	// Count epic title occurrences.
	counts := make(map[string]int)
	for _, task := range tasks {
		if title, ok := epicTitles[task.EpicID]; ok && title != "" {
			counts[title]++
		}
	}

	if len(counts) == 0 {
		return fmt.Sprintf("Phase %d", phaseID)
	}

	// Find the most common epic title; break ties by lexicographic order for determinism.
	var best string
	bestCount := 0
	for title, count := range counts {
		if count > bestCount || (count == bestCount && title < best) {
			best = title
			bestCount = count
		}
	}

	if best == "" {
		return fmt.Sprintf("Phase %d", phaseID)
	}
	return best
}

// reNonAlphanumeric matches any character that is not a lowercase letter, digit, or hyphen.
var reNonAlphanumeric = regexp.MustCompile(`[^a-z0-9-]+`)

// reMultiHyphen matches two or more consecutive hyphens.
var reMultiHyphen = regexp.MustCompile(`-{2,}`)

// Slugify converts a task title to a kebab-case slug suitable for file names.
// It lowercases the title, replaces spaces and special characters with hyphens,
// strips non-ASCII characters, collapses consecutive hyphens, trims leading and
// trailing hyphens, and truncates to 50 characters at a word boundary.
//
// If the result is empty after sanitization, the task's GlobalID is returned as
// a safe fallback.
func Slugify(title string) string {
	// Lowercase.
	s := strings.ToLower(title)

	// Replace spaces with hyphens.
	s = strings.ReplaceAll(s, " ", "-")

	// Strip non-ASCII bytes (keep only ASCII range).
	var ascii strings.Builder
	for _, r := range s {
		if r < 128 {
			ascii.WriteRune(r)
		}
	}
	s = ascii.String()

	// Replace any character that is not a lowercase letter, digit, or hyphen.
	s = reNonAlphanumeric.ReplaceAllString(s, "-")

	// Collapse multiple consecutive hyphens into one.
	s = reMultiHyphen.ReplaceAllString(s, "-")

	// Trim leading and trailing hyphens.
	s = strings.Trim(s, "-")

	// Truncate to 50 characters at the last hyphen boundary.
	const maxSlugLen = 50
	if len(s) > maxSlugLen {
		truncated := s[:maxSlugLen]
		// Find the last hyphen to truncate at a word boundary.
		if idx := strings.LastIndex(truncated, "-"); idx > 0 {
			truncated = truncated[:idx]
		}
		s = truncated
	}

	return s
}

// uniqueSlug returns a collision-free slug for task. It uses usedSlugs to
// track previously assigned slugs and appends "-2", "-3", etc. when needed.
func uniqueSlug(task MergedTask, usedSlugs map[string]int) string {
	base := Slugify(task.Title)
	if base == "" {
		base = strings.ToLower(task.GlobalID)
	}

	slug := base
	if n, exists := usedSlugs[base]; exists {
		n++
		usedSlugs[base] = n
		slug = fmt.Sprintf("%s-%d", base, n+1)
		// Track this derived slug too, to avoid future collisions with it.
		usedSlugs[slug]++
	} else {
		usedSlugs[base] = 0
	}

	return slug
}

// taskFileTemplate is the template used to render individual task spec files.
// Custom delimiters `[[` and `]]` avoid conflicts with `{{` `}}` that may
// appear in task content (e.g., Go code in descriptions).
var taskFileTemplate = template.Must(
	template.New("task").
		Delims("[[", "]]").
		Funcs(template.FuncMap{
			"joinDeps": func(deps []string) string {
				if len(deps) == 0 {
					return "None"
				}
				return strings.Join(deps, ", ")
			},
		}).
		Parse(`# [[ .GlobalID ]]: [[ .Title ]]

## Metadata
| Field | Value |
|-------|-------|
| Priority | [[ .Priority ]] |
| Estimated Effort | [[ .Effort ]] |
| Dependencies | [[ joinDeps .Dependencies ]] |

## Goal
[[ .Description ]]

## Acceptance Criteria
[[ range .AcceptanceCriteria ]]- [ ] [[ . ]]
[[ end ]]`),
)

// renderTaskFile renders a MergedTask into the task spec markdown format.
func renderTaskFile(task MergedTask) ([]byte, error) {
	var buf bytes.Buffer
	if err := taskFileTemplate.Execute(&buf, task); err != nil {
		return nil, fmt.Errorf("executing task file template: %w", err)
	}
	return buf.Bytes(), nil
}

// buildTaskState generates the content of task-state.conf.
// Format: TASK_ID|STATUS|AGENT|TIMESTAMP|NOTES (one line per task, 5 columns).
func (e *Emitter) buildTaskState(tasks []MergedTask) []byte {
	var sb strings.Builder
	sb.WriteString("# Raven Task State -- machine-readable source of truth\n")
	sb.WriteString("# Format: TASK_ID|STATUS|AGENT|TIMESTAMP|NOTES\n")
	sb.WriteString("# STATUS: completed | not_started | in_progress | blocked\n")
	for _, task := range tasks {
		fmt.Fprintf(&sb, "%s|not_started|||\n", task.GlobalID)
	}
	return []byte(sb.String())
}

// buildPhasesConf generates the content of phases.conf.
// Format: ID|Name|StartTask|EndTask (four-field, parseable by task.ParsePhaseLine).
func (e *Emitter) buildPhasesConf(phases []PhaseInfo) []byte {
	var sb strings.Builder
	sb.WriteString("# Raven Phases Configuration\n")
	sb.WriteString("# Format: ID|Name|T-start|T-end\n")
	for _, phase := range phases {
		fmt.Fprintf(&sb, "%d|%s|%s|%s\n", phase.ID, phase.Name, phase.StartTask, phase.EndTask)
	}
	return []byte(sb.String())
}

// buildProgressMD generates the initial content of PROGRESS.md.
func (e *Emitter) buildProgressMD(tasks []MergedTask, phases []PhaseInfo) []byte {
	var sb strings.Builder
	sb.WriteString("# Raven Task Progress Log\n\n")
	sb.WriteString("## Summary\n\n")
	sb.WriteString("| Status | Count |\n")
	sb.WriteString("|--------|-------|\n")
	fmt.Fprintf(&sb, "| Completed | 0 |\n")
	fmt.Fprintf(&sb, "| In Progress | 0 |\n")
	fmt.Fprintf(&sb, "| Not Started | %d |\n", len(tasks))
	sb.WriteString("\n---\n\n")
	sb.WriteString("## Completed Tasks\n\n")

	for _, phase := range phases {
		fmt.Fprintf(&sb, "### Phase %d: %s (%s to %s)\n\n", phase.ID, phase.Name, phase.StartTask, phase.EndTask)
		sb.WriteString("- **Status:** Not Started\n")
		fmt.Fprintf(&sb, "- **Tasks:** %d\n\n", len(phase.Tasks))
	}

	sb.WriteString("---\n\n")
	sb.WriteString("## Completion Log\n\n")
	sb.WriteString("_No tasks completed yet._\n")
	return []byte(sb.String())
}

// buildIndexMD generates the content of INDEX.md.
func (e *Emitter) buildIndexMD(tasks []MergedTask, phases []PhaseInfo) []byte {
	var sb strings.Builder
	sb.WriteString("# Task Index\n\n")
	fmt.Fprintf(&sb, "Total tasks: **%d** | Total phases: **%d**\n\n", len(tasks), len(phases))

	// Task summary table.
	sb.WriteString("## Task Summary\n\n")
	sb.WriteString("| ID | Title | Priority | Effort | Dependencies |\n")
	sb.WriteString("|----|-------|----------|--------|--------------|\n")
	for _, task := range tasks {
		deps := "None"
		if len(task.Dependencies) > 0 {
			deps = strings.Join(task.Dependencies, ", ")
		}
		fmt.Fprintf(&sb, "| %s | %s | %s | %s | %s |\n",
			task.GlobalID,
			escapeMDPipe(task.Title),
			task.Priority,
			task.Effort,
			deps,
		)
	}

	// Phase groupings section.
	sb.WriteString("\n## Phase Groupings\n\n")
	for _, phase := range phases {
		fmt.Fprintf(&sb, "### Phase %d: %s\n\n", phase.ID, phase.Name)
		fmt.Fprintf(&sb, "Tasks: %s to %s (%d tasks)\n\n", phase.StartTask, phase.EndTask, len(phase.Tasks))
		sb.WriteString("| ID | Title |\n")
		sb.WriteString("|----|-------|\n")
		for _, task := range phase.Tasks {
			fmt.Fprintf(&sb, "| %s | %s |\n", task.GlobalID, escapeMDPipe(task.Title))
		}
		sb.WriteString("\n")
	}

	// Dependency overview / Mermaid graph.
	sb.WriteString("## Dependency Overview\n\n")
	if len(tasks) < maxTasksForMermaid {
		mermaid := buildMermaidGraph(tasks)
		if mermaid != "" {
			sb.WriteString("```mermaid\n")
			sb.WriteString(mermaid)
			sb.WriteString("```\n")
		} else {
			sb.WriteString("_No dependencies defined._\n")
		}
	} else {
		fmt.Fprintf(&sb, "_Dependency graph omitted: %d tasks exceed the %d-task limit._\n",
			len(tasks), maxTasksForMermaid)
	}

	return []byte(sb.String())
}

// buildMermaidGraph generates a Mermaid graph TD block from task dependencies.
// Returns an empty string if no tasks have dependencies.
func buildMermaidGraph(tasks []MergedTask) string {
	var lines []string
	for _, task := range tasks {
		for _, dep := range task.Dependencies {
			lines = append(lines, fmt.Sprintf("    %s --> %s", dep, task.GlobalID))
		}
	}
	if len(lines) == 0 {
		return ""
	}
	// Sort for deterministic output.
	sort.Strings(lines)
	return "graph TD\n" + strings.Join(lines, "\n") + "\n"
}

// escapeMDPipe replaces pipe characters in a string with their HTML entity to
// prevent breaking the Markdown table column delimiter.
func escapeMDPipe(s string) string {
	return strings.ReplaceAll(s, "|", "&#124;")
}
